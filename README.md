# Safe Steps ğŸš¶â€â™‚ï¸

Safe Steps is a mobile application meant to support visually impaired users by working in tandem with a smart obstacle-detection belt. It offers real-time feedback (vibration and sound) about obstacles to help users walk more safely and confidently.

---

## ğŸ§­ Table of Contents

- [Features](#features)  
- [Demo / Screenshots](#demo--screenshots)  
- [Tech Stack](#tech-stack)  
- [Getting Started](#getting-started)  
- [Usage](#usage)  
- [Roadmap](#roadmap)  
- [Contributing](#contributing)  
- [License](#license)  
- [Contact](#contact)  

---

## âœ¨ Features

- **Bluetooth Connectivity** â€” Connects with the smart belt to receive sensor data in real time.  
- **Obstacle Detection Alerts** â€” Provides immediate feedback: â€œPATH CLEARâ€ vs â€œOBSTACLE DETECTED.â€  
- **Customizable Feedback**  
  â€¢ Vibration alerts with adjustable intensity (Low / Medium / High)  
  â€¢ Optional sound alerts  
- **Accessible UI** â€” Clean, simple, and intuitive interface for ease of use  
- **Help & Support Section** â€” FAQs, guidance, and contact info included in-app  

---

## ğŸ“· Demo / Screenshots

> _Insert screenshots or mockups from your Canva presentation here._  
> Example markdown you can use:

```md
![Home Screen](./assets/screenshots/home.png)  
![Settings Screen](./assets/screenshots/settings.png)  
![Alert Screen](./assets/screenshots/alert.png)  
ğŸ› ï¸ Tech Stack

Framework: React Native + Expo

Language: TypeScript

Navigation: Expo Router

UI / Graphics: Expo Vector Icons, Expo Linear Gradient

Project Setup / Tools: VS Code, ESLint / Prettier, etc.

ğŸš€ Getting Started
Prerequisites

Node.js and npm (or Yarn) installed

Expo CLI globally:

npm install -g expo-cli

Installation Steps

Clone the repository

git clone https://github.com/Rambo9836/Safe-Steps.git


Move into project folder

cd Safe-Steps


Install dependencies

npm install


Start the development server / run the app

npm run dev

ğŸ“² Usage

Pair the mobile app with the smart belt device via Bluetooth.

As the user walks, the beltâ€™s sensors detect obstacles and send data to the app.

The app triggers vibration and/or sound alerts depending on settings.

The UI shows status like â€œPATH CLEARâ€ or â€œOBSTACLE DETECTED.â€

Users can configure alert strength and toggle sound in settings.

ğŸ“Œ Roadmap & Next Steps

Hardware Integration â€” Connect and test with the physical belt device

User Trials â€” Field testing with visually impaired participants to collect feedback

App Store Deployment â€” Prepare for iOS App Store and Google Play Store release

Voice / Gesture Controls â€” Add voice or gesture input features

Localization â€” Support multiple languages

ğŸ¤ Contributing

Your contributions are welcome! Hereâ€™s how:

Fork the repo

Create a feature branch (git checkout -b feature/YourFeature)

Commit your changes (git commit -m "Add feature")

Push the branch (git push origin feature/YourFeature)

Open a Pull Request
